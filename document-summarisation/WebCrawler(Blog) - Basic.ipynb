{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330df8cd-c716-4364-894f-59cd7d2d7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91905f0c-3e6b-4136-935f-5f88fb5feb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_article_links(url):\n",
    "    \"\"\"Fetch article links from the root page.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch the root page: {url}\")\n",
    "        return {}\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    articles = {}\n",
    "    \n",
    "    # Find all posts under 'post-entry' class\n",
    "    for post in soup.find_all('article', class_='post-entry'):\n",
    "        link_tag = post.find('a', class_='entry-link')\n",
    "        if link_tag:\n",
    "            title = link_tag.get('aria-label', 'No Title').replace(\"post link to \", \"\").strip()\n",
    "            link = link_tag['href']\n",
    "            # Ensure the URL is absolute\n",
    "            full_url = link if link.startswith('http') else BASE_URL + link\n",
    "            articles[title] = full_url\n",
    "    \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19109ad9-fcdc-45b9-830d-40fbd4d2b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_url = \"https://lilianweng.github.io\"\n",
    "article_links = fetch_article_links(root_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9615be-9359-4e7b-b46c-6e08cc06c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_article_links(start_url):\n",
    "    \"\"\"Fetch all article links across multiple pages.\"\"\"\n",
    "    current_url = start_url\n",
    "    articles = {}\n",
    "\n",
    "    while current_url:\n",
    "        print(f\"Fetching page: {current_url}\")\n",
    "        response = requests.get(current_url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch the page: {current_url}\")\n",
    "            break\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find articles on the current page\n",
    "        for post in soup.find_all('article', class_='post-entry'):\n",
    "            link_tag = post.find('a', class_='entry-link')\n",
    "            if link_tag:\n",
    "                title = link_tag.get('aria-label', 'No Title').replace(\"post link to \", \"\").strip()\n",
    "                link = link_tag['href']\n",
    "                full_url = link if link.startswith('http') else BASE_URL + link\n",
    "                articles[title] = full_url\n",
    "\n",
    "        # Check for the \"Next\" link in the page-footer\n",
    "        next_page_tag = soup.find('footer', class_='page-footer').find('a', class_='next')\n",
    "        if next_page_tag and 'href' in next_page_tag.attrs:\n",
    "            next_page = next_page_tag['href']\n",
    "            current_url = next_page if next_page.startswith('http') else BASE_URL + next_page\n",
    "        else:\n",
    "            # No more pages\n",
    "            current_url = None\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602756e-3f54-4abd-bea8-4bf711a8e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_links = fetch_all_article_links(root_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe146e4c-e429-49b2-8de0-8658a7d39784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"Article Links:\")\n",
    "for title, link in article_links.items():\n",
    "    print(f\"Title: {title}, Link: {link}\")\n",
    "    \n",
    "with open('article_links.json', 'w') as f:\n",
    "    json.dump(article_links, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380049f8-82b8-4d94-9fc4-1f38540de806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_article_content(url):\n",
    "    \"\"\"Fetch and parse the content of an individual article.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch article: {url}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    content_div = soup.find('div', class_='post-content')\n",
    "    return content_div.text.strip() if content_div else \"Content not found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b139b-9ae8-4dca-84fd-0c78473f0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = {}\n",
    "for title, link in article_links.items():\n",
    "        print(f\"\\nFetching content for: {title}\")\n",
    "        content = fetch_article_content(link)\n",
    "        articles[title] = content\n",
    "        print(f\"Content Preview:\\n{content[:500]}...\")  # Show first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb830758-263b-4639-a610-30d0ec31b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('articles.json', 'w') as f:\n",
    "    json.dump(articles, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c6990-5861-4591-a23a-7c019318e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('article_links.json', 'r') as f:\n",
    "    article_li = json.load(f)\n",
    "print(article_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6556ed-4296-4e6b-abb4-3da5d768f850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
